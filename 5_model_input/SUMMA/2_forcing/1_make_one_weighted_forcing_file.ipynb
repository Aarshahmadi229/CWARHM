{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create one (1) area-weighted forcing file\n",
    "We need to find how the ERA5 gridded forcing maps onto the catchment to create area-weighted forcing as SUMMA input. This involves two steps:\n",
    "1. Intersect the ERA5 shape with the user's catchment shape to find the overlap between a given (sub) catchment and the forcing grid;\n",
    "2. Create an area-weighted, catchment-averaged forcing time series.\n",
    "\n",
    "The CANDEX package (https://github.com/ShervanGharari/candex_newgen) provides the necessary functionality to do this. CANDEX performs the GIS step (1, shapefile intersection) and the area-weighting step (2, create new forcing `.nc` files) as part of a single `run_candex()` call. To allow for parallelization, CANDEX can save the output from the GIS step into a restart `.csv` file which can be used to skip the GIS step. This allows (manual) parallelization of area-weighted forcing file generation after the GIS procedures have been run once. The full workflow here is thus:\n",
    "1. [This script] Call `run_candex()` with ERA5 and user's shapefile, and one ERA5 forcing `.nc` file;\n",
    "    - CANDEX performs intersection of both shapefiles;\n",
    "    - CANDEX saves the outcomes of this intersection to a `.csv` file;\n",
    "    - CANDEX creates an area-weighted forcing file from a single provided ERA5 source `.nc` file\n",
    "2. [Follow-up script] Call `run_candex()` with intersection `.csv` file and all other forcing `.nc` files.\n",
    "3. [Follow-up script] Apply lapse rates to temperature variable.\n",
    "\n",
    "Parallelization of step 2 (2nd `run_candex()` call) requires an external loop that sends (batches of) the remaining ERA5 raw forcing files to individual processors. As with other steps that may be parallelized, creating code that does this is left to the user.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import os\n",
    "import glob\n",
    "import candex\n",
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "from shutil import copyfile\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control file handling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy access to control file folder\n",
    "controlFolder = Path('../../../0_control_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the name of the 'active' file in a variable\n",
    "controlFile = 'control_active.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract a given setting from the control file\n",
    "def read_from_control( file, setting ):\n",
    "    \n",
    "    # Open 'control_active.txt' and ...\n",
    "    with open(file) as contents:\n",
    "        for line in contents:\n",
    "            \n",
    "            # ... find the line with the requested setting\n",
    "            if setting in line:\n",
    "                break\n",
    "    \n",
    "    # Extract the setting's value\n",
    "    substring = line.split('|',1)[1]      # Remove the setting's name (split into 2 based on '|', keep only 2nd part)\n",
    "    substring = substring.split('#',1)[0] # Remove comments, does nothing if no '#' is found\n",
    "    substring = substring.strip()         # Remove leading and trailing whitespace, tabs, newlines\n",
    "       \n",
    "    # Return this value    \n",
    "    return substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to specify a default path\n",
    "def make_default_path(suffix):\n",
    "    \n",
    "    # Get the root path\n",
    "    rootPath = Path( read_from_control(controlFolder/controlFile,'root_path') )\n",
    "    \n",
    "    # Get the domain folder\n",
    "    domainName = read_from_control(controlFolder/controlFile,'domain_name')\n",
    "    domainFolder = 'domain_' + domainName\n",
    "    \n",
    "    # Specify the forcing path\n",
    "    defaultPath = rootPath / domainFolder / suffix\n",
    "    \n",
    "    return defaultPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find location of shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catchment shapefile path & name\n",
    "catchment_path = read_from_control(controlFolder/controlFile,'intersect_dem_path')\n",
    "catchment_name = read_from_control(controlFolder/controlFile,'intersect_dem_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify default path if needed\n",
    "if catchment_path == 'default':\n",
    "    catchment_path = make_default_path('shapefiles/catchment_intersection/with_dem') # outputs a Path()\n",
    "else:\n",
    "    catchment_path = Path(catchment_path) # make sure a user-specified path is a Path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forcing shapefile path & name\n",
    "forcing_shape_path = read_from_control(controlFolder/controlFile,'forcing_shape_path')\n",
    "forcing_shape_name = read_from_control(controlFolder/controlFile,'forcing_shape_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify default path if needed\n",
    "if forcing_shape_path == 'default':\n",
    "    forcing_shape_path = make_default_path('shapefiles/forcing') # outputs a Path()\n",
    "else:\n",
    "    forcing_shape_path = Path(forcing_shape_path) # make sure a user-specified path is a Path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find where the intersection needs to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersected shapefile path. Name is set by CANDEX as [prefix]_intersected_shapefile.shp\n",
    "intersect_path = read_from_control(controlFolder/controlFile,'intersect_forcing_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify default path if needed\n",
    "if intersect_path == 'default':\n",
    "    intersect_path = make_default_path('shapefiles/catchment_intersection/with_forcing') # outputs a Path()\n",
    "else:\n",
    "    intersect_path = Path(intersect_path) # make sure a user-specified path is a Path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the folder if it doesn't exist\n",
    "intersect_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the forcing files (merged ERA5 data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of merged ERA5 files\n",
    "forcing_merged_path = read_from_control(controlFolder/controlFile,'forcing_merged_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify default path if needed\n",
    "if forcing_merged_path == 'default':\n",
    "    forcing_merged_path = make_default_path('forcing/2_merged_data') # outputs a Path()\n",
    "else:\n",
    "    forcing_merged_path = Path(forcing_merged_path) # make sure a user-specified path is a Path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files in folder\n",
    "forcing_files = [forcing_merged_path/file for file in os.listdir(forcing_merged_path) if os.path.isfile(forcing_merged_path/file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the files\n",
    "forcing_files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find where the temporary CANDEX files need to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location for CANDEX temporary storage\n",
    "forcing_candex_path = read_from_control(controlFolder/controlFile,'forcing_candex_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify default path if needed\n",
    "if forcing_candex_path == 'default':\n",
    "    forcing_candex_path = make_default_path('forcing/3_temp_candex') # outputs a Path()\n",
    "else:\n",
    "    forcing_candex_path = Path(forcing_candex_path) # make sure a user-specified path is a Path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the folder if it doesn't exist\n",
    "forcing_candex_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find where the area-weighted forcing needs to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location for CANDEX forcing output\n",
    "forcing_basin_path = read_from_control(controlFolder/controlFile,'forcing_basin_avg_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify default path if needed\n",
    "if forcing_basin_path == 'default':\n",
    "    forcing_basin_path = make_default_path('forcing/3_basin_averaged_data') # outputs a Path()\n",
    "else:\n",
    "    forcing_basin_path = Path(forcing_basin_path) # make sure a user-specified path is a Path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the folder if it doesn't exist\n",
    "forcing_basin_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CANDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a CANDEX object\n",
    "cndx = candex.candex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author name\n",
    "cndx.author_name = 'SUMMA public workflow scripts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data license\n",
    "cndx.license = 'Copernicus data use license: https://cds.climate.copernicus.eu/api/v2/terms/static/licence-to-use-copernicus-products.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case name, used in CANDEX-generated file naes\n",
    "cndx.case_name = read_from_control(controlFolder/controlFile,'domain_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA5 shapefile and variable names\n",
    "# Variable names can be hardcoded because we set them when we generate this shapefile as part of the workflow\n",
    "cndx.source_shp     = forcing_shape_path/forcing_shape_name # shapefile\n",
    "cndx.source_shp_lat = 'lat'                                 # name of the latitude field\n",
    "cndx.source_shp_lon = 'lon'                                 # name of the longitude field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catchment shapefile and variable names\n",
    "cndx.sink_shp = catchment_path/catchment_name\n",
    "cndx.sink_shp_ID  = read_from_control(controlFolder/controlFile,'catchment_shp_hruid') # name of the HRU ID field\n",
    "cndx.sink_shp_lat = read_from_control(controlFolder/controlFile,'catchment_shp_lat')   # name of the latitude field\n",
    "cndx.sink_shp_lon = read_from_control(controlFolder/controlFile,'catchment_shp_lon')   # name of the longitude field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA5 netcdf file and variable names\n",
    "cndx.source_nc = str(forcing_files[0]) # first file in the list; Path() to string\n",
    "cndx.var_names = ['airpres',\n",
    "                  'LWRadAtm',\n",
    "                  'SWRadAtm',\n",
    "                  'pptrate',\n",
    "                  'airtemp',\n",
    "                  'spechum',\n",
    "                  'windspd'] # variable names of forcing data - hardcoded because we prescribe them during ERA5 merging\n",
    "cndx.var_lat   = 'latitude'  # name of the latitude dimensions\n",
    "cndx.var_lon   = 'longitude' # name of the longitude dimension\n",
    "cndx.var_time  = 'time'      # name of the time dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary folder where the CANDEX-generated GIS files and remapping file will be saved\n",
    "cndx.temp_dir = str(forcing_candex_path) + '/' # Path() to string; ensure the trailing '/' CANDEX wants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output folder where the catchment-averaged forcing will be saved\n",
    "cndx.output_dir = str(forcing_basin_path) + '/' # Path() to string; ensure the trailing '/' CANDEX wants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netcdf settings\n",
    "cndx.remapped_dim_id = 'hru'     # name of the non-time dimension; prescribed by SUMMA\n",
    "cndx.remapped_var_id = 'hruId'   # name of the variable associated with the non-time dimension\n",
    "cndx.format_list     = ['f4']    # variable type to save forcing as. Single entry here will be used for all variables\n",
    "cndx.fill_value_list = ['-9999'] # fill value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag that we do not want the data stored in .csv in addition to .nc\n",
    "cndx.save_csv  = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag that we currently have no remapping file\n",
    "cndx.remap_csv = ''   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candex is given multiple varibales to be remapped but only on format and fill valuecandex repeat the format and fill value for all the variables in output files\n",
      "candex detects that target shapefile is in WGS84 (epsg:4326)\n",
      "candex detects that the field for ID is provided in sink/target shapefile\n",
      "candex detects that the field latitude is provided in sink/target shapefile\n",
      "candex detects that the field longitude is provided in sink/target shapefile\n",
      "it seems everything is OK with the sink/target shapefile; added to candex object sink_shp_gpd\n",
      "candex will save standard shapefile for candex claculation as:\n",
      "C:\\Globus endpoint\\summaWorkflow_data\\domain_BowAtBanff\\forcing\\3_temp_candex/BowAtBanff_sink_shapefile.shp\n",
      "candex detects that the varibales from the netCDF files are identicalin dimensions of the varibales and latitude and longitude\n",
      "candex detects that all the varibales have dimensions of:\n",
      "['time', 'latitude', 'longitude']\n",
      "candex detects that the longitude varibales has dimensions of:\n",
      "['longitude']\n",
      "candex detects that the latitude varibales has dimensions of:\n",
      "['latitude']\n",
      "candex detects case 1 - regular lat/lon\n",
      "[-0.25]\n",
      "(1,)\n",
      "[0.25]\n",
      "(1,)\n",
      "candex detect the shapefile is provided and will resave it here:\n",
      "C:\\Globus endpoint\\summaWorkflow_data\\domain_BowAtBanff\\forcing\\3_temp_candex/BowAtBanff_source_shapefile.shp\n",
      "-116.875 50.625 -115.375 51.875\n",
      "candex decides the netCDF file has longtitude values of -180 to 180; creating the extended\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmk934\\Anaconda3\\envs\\geospatialTools_qgis_candex\\lib\\site-packages\\candex\\candex.py:109: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shp_2 ['lat_temp'] = shp_2.centroid.y\n",
      "C:\\Users\\wmk934\\Anaconda3\\envs\\geospatialTools_qgis_candex\\lib\\site-packages\\candex\\candex.py:110: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shp_2 ['lon_temp'] = shp_2.centroid.x\n",
      "C:\\Users\\wmk934\\Anaconda3\\envs\\geospatialTools_qgis_candex\\lib\\site-packages\\candex\\candex.py:893: FutureWarning: Assigning CRS to a GeoDataFrame without a geometry column is now deprecated and will not be supported in the future.\n",
      "  pairs = gpd.GeoDataFrame(nei, columns=['idx1','idx2'], crs=df1.crs)\n",
      "C:\\Users\\wmk934\\Anaconda3\\envs\\geospatialTools_qgis_candex\\lib\\site-packages\\candex\\candex.py:897: FutureWarning: Assigning CRS to a GeoDataFrame without a geometry column is now deprecated and will not be supported in the future.\n",
      "  pairs = gpd.GeoDataFrame(pairs, columns=pairs.columns, crs=df1.crs)\n",
      "C:\\Users\\wmk934\\Anaconda3\\envs\\geospatialTools_qgis_candex\\lib\\site-packages\\candex\\candex.py:135: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_int.to_file(self.temp_dir+self.case_name+'_intersected_shapefile.shp') # save the intersected files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------REMAPPING------\n",
      "Remapping C:\\Globus endpoint\\summaWorkflow_data\\domain_BowAtBanff\\forcing\\2_merged_data\\ERA5_merged_197901.nc to C:\\Globus endpoint\\summaWorkflow_data\\domain_BowAtBanff\\forcing\\3_basin_averaged_data/BowAtBanff_remapped_1979-01-01-00-00-00.nc\n",
      "Started at date and time 2021-03-18 11:03:12.237417\n",
      "Ended   at date and time 2021-03-18 11:03:42.227872\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "# Run candex\n",
    "# Note on centroid warnings: in this case we use a regular lat/lon grid to represent ERA5 forcing and ...\n",
    "#     centroid estimates without reprojecting are therefore acceptable.\n",
    "# Note on deprecation warnings: this is a CANDEX issue that cannot be resolved here. Does not affect current use.\n",
    "cndx.run_candex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move files to prescribed locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remapping file \n",
    "remap_file = cndx.case_name + '_remapping.csv'\n",
    "copyfile( cndx.temp_dir + remap_file, intersect_path / remap_file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersected shapefile\n",
    "for file in glob.glob(cndx.temp_dir + cndx.case_name + '_intersected_shapefile.*'):\n",
    "    copyfile( file, intersect_path / os.path.basename(file));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the temporary CANDEX directory to save space\n",
    "try:\n",
    "    rmtree(cndx.temp_dir)\n",
    "except OSError as e:\n",
    "    print (\"Error: %s - %s.\" % (e.filename, e.strerror))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code provenance - intersection shapefile\n",
    "Generates a basic log file in the domain folder and copies the control file and itself there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the log path and file name\n",
    "logPath = intersect_path\n",
    "log_suffix = '_catchment_forcing_intersect_log.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log folder\n",
    "logFolder = '_workflow_log'\n",
    "Path( logPath / logFolder ).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy this script\n",
    "thisFile = '1_make_one_weighted_forcing_file.ipynb'\n",
    "copyfile(thisFile, logPath / logFolder / thisFile);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current date and time\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log file \n",
    "logFile = now.strftime('%Y%m%d') + log_suffix\n",
    "with open( logPath / logFolder / logFile, 'w') as file:\n",
    "    \n",
    "    lines = ['Log generated by ' + thisFile + ' on ' + now.strftime('%Y/%m/%d %H:%M:%S') + '\\n',\n",
    "             'Intersect shapefiles of catchment and ERA5.']\n",
    "    for txt in lines:\n",
    "        file.write(txt)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code provenance - weighted forcing file\n",
    "Generates a basic log file in the domain folder and copies the control file and itself there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the log path and file name\n",
    "logPath = forcing_basin_path\n",
    "log_suffix = '_create_one_weighted_forcing_file_log.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log folder\n",
    "logFolder = '_workflow_log'\n",
    "Path( logPath / logFolder ).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy this script\n",
    "thisFile = '1_make_one_weighted_forcing_file.ipynb'\n",
    "copyfile(thisFile, logPath / logFolder / thisFile);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current date and time\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log file \n",
    "logFile = now.strftime('%Y%m%d') + log_suffix\n",
    "with open( logPath / logFolder / logFile, 'w') as file:\n",
    "    \n",
    "    lines = ['Log generated by ' + thisFile + ' on ' + now.strftime('%Y/%m/%d %H:%M:%S') + '\\n',\n",
    "             'Made a weighted forcing file based on intersect shapefiles of catchment and ERA5.']\n",
    "    for txt in lines:\n",
    "        file.write(txt)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geospatialTools_qgis_candex]",
   "language": "python",
   "name": "conda-env-geospatialTools_qgis_candex-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
