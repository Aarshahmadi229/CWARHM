{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERA5 sanity check\n",
    "Checks if forcing data in merged ERA5 files are all:\n",
    "- Within user-specified ranges;\n",
    "- Not missing;\n",
    "- Not NaN.\n",
    "\n",
    "Also checks the time dimension in each file to find if timesteps are:\n",
    "- Not NaN;\n",
    "- Consecutive;\n",
    "- Equidistant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of merged files\n",
    "path_to_data = Path( 'C:/Globus endpoint/summaWorkflow_data/domain_BowAtBanff/forcing/2_merged_data' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location and name of logfile\n",
    "log_folder = path_to_data / 'sanity_checks'\n",
    "log_file = 'log_sanity_checks.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File pattern\n",
    "file_base = 'ERA5_merged_'\n",
    "file_end = '.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years to check (Jan-years[0] to Dec-years[1])\n",
    "years = [1979,1979]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feasible variable ranges\n",
    "ranges = {\n",
    "    'pptrate': [0,float('inf')],\n",
    "    'airpres': [0,float('inf')],\n",
    "    'airtemp': [173,373],\n",
    "    'spechum': [0,float('inf')],\n",
    "    'SWRadAtm': [0,float('inf')],\n",
    "    'LWRadAtm': [0,float('inf')],\n",
    "    'windspd': [0,float('inf')],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables we want to check\n",
    "var_names = {'time','pptrate','airpres','airtemp','spechum','SWRadAtm','LWRadAtm','windspd'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the output folder if doesn't exist\n",
    "log_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a dictionary to store results in\n",
    "report = {\n",
    "    'file name': [],\n",
    "    'data type': [],\n",
    "    'data unit': [],\n",
    "    'num NaNs': [],\n",
    "    'num missing': [],\n",
    "    'num < min': [],\n",
    "    'num > max': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the log file\n",
    "logFile = open(log_folder / log_file,'w')\n",
    "\n",
    "# log start\n",
    "logFile.write('Opened for writing on ' + str(datetime.now()) + '\\n');\n",
    "\n",
    "# Loop over variables first, so that reports aggregated per variable for easy comparison\n",
    "for var in var_names:\n",
    "\n",
    "    # Print where we are\n",
    "    logFile.write('\\n')\n",
    "    logFile.write('Now checking variable // ' + var + ' // \\n')\n",
    "    if var == 'time':\n",
    "        logFile.write(\"{:20} {:10} {:35} {:10} {:15} {:15}\\n\".format('file_name','data_type','data_unit','num_NaNs','consecutive?','equidistant?'))\n",
    "    else:\n",
    "        logFile.write(\"{:20} {:10} {:35} {:10} {:12} {:10} {:10}\\n\".format('file_name','data_type','data_unit','num_NaNs','num_missing','num_<_min','num_>_max'))\n",
    "    \n",
    "    # Loop over all files (year & month)\n",
    "    for year in range(years[0],years[1]+1):\n",
    "        for month in range(1,13):\n",
    "        \n",
    "            # Specify the file name\n",
    "            file_name = (file_base + str(year) + str(month).zfill(2) + file_end)\n",
    "            file_full = path_to_data / file_name\n",
    "\n",
    "            # Check if this file exists\n",
    "            if not os.path.isfile(file_full):\n",
    "                continue\n",
    "        \n",
    "            # Open netcdf file for specific year and month\n",
    "            with nc4.Dataset(file_full) as src:\n",
    "            \n",
    "                # Extract the variable into a numpy array\n",
    "                dat = np.array(src[var][:])\n",
    "                \n",
    "                # Get basic information\n",
    "                chk_size = dat.shape\n",
    "                chk_isnan = np.isnan(dat).sum()\n",
    "                \n",
    "                # Get the information that depends on attributes\n",
    "                try: chk_type = src[var].dtype\n",
    "                except: chk_type = 'n/a'\n",
    "                \n",
    "                try: chk_units = src[var].units\n",
    "                except: chk_units = 'n/a'\n",
    "                \n",
    "                try:\n",
    "                    chk_missv = src[var].missing_value\n",
    "                    chk_missn = (dat == chk_missv).sum()\n",
    "                except:\n",
    "                    chk_missv = chk_missn = 'n/a'\n",
    "                \n",
    "                # Count how often the data goes beyond the defined 'sane' ranges\n",
    "                if var in ranges:\n",
    "                    chk_min = ranges[var][0]\n",
    "                    chk_max = ranges[var][1]                    \n",
    "                    chk_under = (dat < chk_min).sum()\n",
    "                    chk_over = (dat > chk_max).sum()\n",
    "                else:\n",
    "                    chk_under = 'n/a'\n",
    "                    chk_over = 'n/a'\n",
    "                \n",
    "                # Check if time values are consecutive and equidistant\n",
    "                if var == 'time':\n",
    "                    if all(np.sort(dat) == dat): chk_cons = True \n",
    "                    else: chk_cons = False\n",
    "                    if all(np.diff(dat) == 1): chk_equid = True \n",
    "                    else: chk_equid = False                    \n",
    "                \n",
    "                # update the dictionary\n",
    "                report['file name'].append(file_name)\n",
    "                report['data type'].append(chk_type)\n",
    "                report['data unit'].append(chk_units)\n",
    "                report['num NaNs'].append(chk_isnan)\n",
    "                report['num missing'].append(chk_missn)\n",
    "                report['num < min'].append(chk_under)\n",
    "                report['num > max'].append(chk_over)\n",
    "                \n",
    "                # print to file\n",
    "                if var == 'time':\n",
    "                    logFile.write(\"{:20} {:10} {:35} {:10} {:15} {:15}\\n\".format(str(file_name),\n",
    "                                                                                str(chk_type),\n",
    "                                                                                str(chk_units),\n",
    "                                                                                str(chk_isnan),\n",
    "                                                                                str(chk_cons),\n",
    "                                                                                str(chk_equid)))\n",
    "                else:\n",
    "                    logFile.write(\"{:20} {:10} {:35} {:10} {:12} {:10} {:10}\\n\".format(str(file_name),\n",
    "                                                                                str(chk_type),\n",
    "                                                                                str(chk_units),\n",
    "                                                                                str(chk_isnan),\n",
    "                                                                                str(chk_missn),\n",
    "                                                                                str(chk_under),\n",
    "                                                                                str(chk_over)))\n",
    "                    \n",
    "# log end\n",
    "logFile.write('\\n')\n",
    "logFile.write('Finished on ' + str(datetime.now()) + '\\n');\n",
    "\n",
    "# File handling\n",
    "logFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geospatialTools]",
   "language": "python",
   "name": "conda-env-geospatialTools-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
